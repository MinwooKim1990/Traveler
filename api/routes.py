# %%
import os
import logging
import asyncio
import concurrent.futures
import time
import uuid
import json
from pathlib import Path
from flask import Flask, request, jsonify
from config import API_KEY, UPLOAD_FOLDER, RESPONSE_FOLDER
from discord_bot import bot, send_location_to_discord
from utils.gemini import gemini_bot
from utils.audio_convert import convert_m4a_to_mp3_moviepy
from utils.whisper_gen import transcribe_audio, synthesize_speech
from utils import search_nearby_places as maps_search_nearby
from utils.image_resize import resize_image
from datetime import datetime
from timezonefinder import TimezoneFinder
import pytz
from google import genai
from config import GEMINI_API_KEY
from duckduckgo_search import DDGS
import PIL.Image

def get_search_results(query: str):
    results = []
    pages = 2
    try:
        ddg_results = DDGS().text(query, max_results=pages * 20)
        for item in ddg_results:
            href = item.get("href")
            if not href:
                continue
            parts = href.split("/")
            domain = parts[2] if len(parts) > 2 else ""
            result_item = {
                "kind": "duckduckgo#result",
                "title": item.get("title", "").strip(),
                "link": href.strip(),
                "snippet": item.get("body", "").strip(),
                "displayLink": domain
            }
            # ë™ì¼ ë„ë©”ì¸ ê²°ê³¼ ì œì™¸
            if all(r['displayLink'] != domain for r in results):
                results.append(result_item)
    except Exception as e:
        print(f"DuckDuckGo ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
    return results

def get_local_time_by_gps(lat, lng):
    tf = TimezoneFinder()
    tz_name = tf.timezone_at(lng=float(lng), lat=float(lat))
    if not tz_name:
        tz_name = "UTC"  # ê¸°ë³¸ê°’: UTC
    local_tz = pytz.timezone(tz_name)
    return datetime.now(local_tz).strftime("%Y-%m-%d %H:%M:%S")

def generate_content_with_history(system_prompt: str, new_message: str, function_list: list = None, image_path: str = None, k: int = 7, history: list = None):
    
    # íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”: ì „ë‹¬ëœ íˆìŠ¤í† ë¦¬ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ìƒì„±
    if history is None:
        history = []
    
    # ìµœì‹  k í„´ì˜ íˆìŠ¤í† ë¦¬ë§Œ ìœ ì§€ (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ëŠ” í•­ìƒ ë§¨ ì•ì— ìœ ì§€)
    if len(history) > k:
        history = history[-k:]
    
    # ëŒ€í™” ë‚´ìš© êµ¬ì„±: Gemini APIì— ë§ëŠ” í˜•ì‹ìœ¼ë¡œ êµ¬ì„±
    client = genai.Client(api_key=GEMINI_API_KEY)
    
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    system_message = {"role": "system", "parts": [{"text": system_prompt}]}
    
    try:
        if image_path is None:
            print("No image conversation")
            
            if function_list is not None:
                print("Function list")
                config = {"tools": function_list}
                response = client.models.generate_content(
                    model='gemini-2.0-flash-lite',
                    config=config,
                    contents=[system_prompt, new_message]
                )
            else:
                print("No function list")
                response = client.models.generate_content(
                    model='gemini-2.0-flash-lite',
                    contents=[system_prompt, new_message]
                )
            
        else:
            print("Image conversation")
            image = PIL.Image.open(image_path)
            
            if function_list is not None:
                print("Function list with image")
                config = {"tools": function_list}
                response = client.models.generate_content(
                    model='gemini-2.0-flash-lite',
                    config=config,
                    contents=[system_prompt, new_message, image]
                )
            else:
                print("No function list with image")
                response = client.models.generate_content(
                    model='gemini-2.0-flash-lite',
                    contents=[system_prompt, new_message, image]
                )
        
        # íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
        history.append({"role": "user", "content": new_message})
        history.append({"role": "assistant", "content": response.text})
        
        print(response.text)
        return history
    except ValueError as ve:
        print("ValueErrorê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:", ve)
        return history
    except Exception as e:
        print("ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:", e)
        return history
    
# ì‘ë‹µ ì €ì¥ í´ë” ìƒì„±
os.makedirs(RESPONSE_FOLDER, exist_ok=True)

app = Flask(__name__)

def generate_unique_filename(prefix, original_filename):
    """
    ê³ ìœ í•œ íŒŒì¼ ì´ë¦„ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Parameters:
        prefix: íŒŒì¼ ì´ë¦„ ì ‘ë‘ì‚¬ ('image' ë˜ëŠ” 'audio')
        original_filename: ì›ë³¸ íŒŒì¼ ì´ë¦„
        
    Returns:
        ìƒì„±ëœ ê³ ìœ  íŒŒì¼ ì´ë¦„
    """
    # í™•ì¥ì ì¶”ì¶œ
    _, file_extension = os.path.splitext(original_filename)
    
    # í˜„ì¬ ì‹œê°„ê³¼ UUIDë¥¼ ì‚¬ìš©í•˜ì—¬ ê³ ìœ í•œ ë²ˆí˜¸ ìƒì„±
    unique_id = int(time.time() * 1000) % 100000
    
    # ìƒˆ íŒŒì¼ ì´ë¦„ í˜•ì‹: image_12345.jpg ë˜ëŠ” audio_12345.mp3
    return f"{prefix}_{unique_id}{file_extension}"

def create_restaurant_system_prompt(latitude, longitude, places):
    """
    ì£¼ë³€ ì‹ë‹¹ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Parameters:
        latitude: í˜„ì¬ ìœ„ì¹˜ì˜ ìœ„ë„
        longitude: í˜„ì¬ ìœ„ì¹˜ì˜ ê²½ë„
        places: ì£¼ë³€ ì¥ì†Œ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
    """
    prompt = f"""
ë‹¹ì‹ ì€ í˜„ì¬ ìœ„ì¹˜(ìœ„ë„: {latitude}, ê²½ë„: {longitude})ì— ìˆëŠ” ì—¬í–‰ìì—ê²Œ ë§›ì§‘ì„ ì¶”ì²œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒì€ ì£¼ë³€ì—ì„œ ì°¾ì€ ì‹ë‹¹ ì •ë³´ì…ë‹ˆë‹¤:

"""
    
    for i, place in enumerate(places, 1):
        prompt += f"""
ì‹ë‹¹ {i}: {place['name']}
- ê±°ë¦¬: {place['distance']:.2f}km
- í‰ì : {place.get('rating', 'ì •ë³´ ì—†ìŒ')}
- ì˜ì—… ì—¬ë¶€: {'ì˜ì—… ì¤‘' if place.get('open_now') else 'ì˜ì—… ì¢…ë£Œ ë˜ëŠ” ì •ë³´ ì—†ìŒ'}
- ìœ í˜•: {', '.join(place.get('types', ['ì •ë³´ ì—†ìŒ']))}
"""
    
    prompt += """
ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ì‹ë‹¹ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”. ê° ì‹ë‹¹ì˜ ì¥ì ê³¼ íŠ¹ì§•, ì–´ë–¤ ìŒì‹ì´ ë§›ìˆì„ì§€ ì„¤ëª…í•˜ê³ , 
ì‚¬ìš©ìì˜ ìœ„ì¹˜ì—ì„œ ê°€ê¹Œìš´ ìˆœì„œë¡œ ìš°ì„  ì¶”ì²œí•´ì£¼ì„¸ìš”. í•œêµ­ì–´ë¡œ ìƒì„¸í•˜ê²Œ ì¹œì ˆí•œ ë§íˆ¬ë¡œ ëŒ€ë‹µí•´ì£¼ì„¸ìš”.
"""
    return prompt

def process_image_prompt(latitude, longitude, image_path):
    """
    ì´ë¯¸ì§€ì™€ GPS ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Parameters:
        latitude: í˜„ì¬ ìœ„ì¹˜ì˜ ìœ„ë„
        longitude: í˜„ì¬ ìœ„ì¹˜ì˜ ê²½ë„
        image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        
    Returns:
        ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
    """
    return f"""
ë‹¹ì‹ ì€ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì œê³µëœ ì´ë¯¸ì§€ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ë¯¸ì§€ì˜ ì£¼ìš” ë‚´ìš©ê³¼ íŠ¹ì§•ì„ ê°„ë‹¨íˆ ì„¤ëª…í•˜ê³ ,
ì—¬í–‰ìì—ê²Œ ë„ì›€ì´ ë  ì¶”ì²œ ì´ìœ ë¥¼ ì¹œì ˆí•˜ê²Œ ì œê³µí•´ì£¼ì„¸ìš”.

í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
"""

@app.route('/upload', methods=['POST'])
def receive_data():
    """ìœ„ì¹˜ ì •ë³´, ì´ë¯¸ì§€, ìŒì„± ë“±ì˜ ë°ì´í„°ë¥¼ ë°›ì•„ ì²˜ë¦¬í•˜ëŠ” API ì—”ë“œí¬ì¸íŠ¸
    
    Returns:
        JSON ì‘ë‹µ ë° HTTP ìƒíƒœ ì½”ë“œ
    """
    try:
        discord_sent = False  # Discord ë©”ì‹œì§€ ì „ì†¡ ì—¬ë¶€ í”Œë˜ê·¸
        # API Key ê²€ì¦
        key = request.headers.get("X-API-Key")
        if key != API_KEY:
            return jsonify({"error": "Invalid API Key"}), 403

        # ğŸŒ GPS ë°ì´í„° ë°›ê¸° (form-dataì˜ text í•„ë“œì— key=value í˜•íƒœë¡œ ì „ë‹¬)
        gps_data = request.form.get("text", "")
        gps_lines = gps_data.split("\n")
        gps_dict = {}
        
        for line in gps_lines:
            if "=" in line:
                k, v = line.split("=", 1)
                gps_dict[k.strip()] = v.strip()
                
        latitude = gps_dict.get("latitude", "")
        longitude = gps_dict.get("longitude", "")
        street = gps_dict.get("street", "")
        city = gps_dict.get("city", "")

        # ì—…ë¡œë“œ í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        os.makedirs(UPLOAD_FOLDER, exist_ok=True)

        # ğŸ“¸ ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬ (ì—†ìœ¼ë©´ None)
        image = request.files.get("image")
        image_filename = None
        
        if image and image.filename:
            # ê³ ìœ í•œ ì´ë¯¸ì§€ íŒŒì¼ ì´ë¦„ ìƒì„±
            new_image_filename = generate_unique_filename("image", image.filename)
            image_filename = os.path.join(UPLOAD_FOLDER, new_image_filename)
            image.save(image_filename)
            logging.debug(f"ì´ë¯¸ì§€ ì €ì¥: {image_filename} (ì›ë³¸: {image.filename})")

        # ğŸ¤ ìŒì„± íŒŒì¼ ì²˜ë¦¬ (ì—†ìœ¼ë©´ None)
        audio = request.files.get("voice")
        audio_filename = None
        
        if audio and audio.filename:
            # ê³ ìœ í•œ ì˜¤ë””ì˜¤ íŒŒì¼ ì´ë¦„ ìƒì„±
            new_audio_filename = generate_unique_filename("audio", audio.filename)
            audio_filename = os.path.join(UPLOAD_FOLDER, new_audio_filename)
            audio.save(audio_filename)
            logging.debug(f"ìŒì„± ì €ì¥: {audio_filename} (ì›ë³¸: {audio.filename})")

        # ğŸ’¬ ì¶”ê°€ ë©”ì‹œì§€ ì²˜ë¦¬
        extra_message = request.form.get("message", "")
        
        # LLM ë° ì²˜ë¦¬ ê²°ê³¼ë¥¼ ì €ì¥í•  ë³€ìˆ˜
        llm_response = None
        response_audio = None
        
        # 1. GPSë§Œ ìˆëŠ” ê²½ìš° - ì£¼ë³€ ë§›ì§‘ ì¶”ì²œ (function call ì‚¬ìš©)
        if latitude and longitude and not image_filename and not audio_filename and not extra_message:
            logging.info("ì¼€ì´ìŠ¤ 1: GPS ì •ë³´ë§Œ ìˆëŠ” ê²½ìš° - ì£¼ë³€ ë§›ì§‘ ì¶”ì²œ")

            user_preference = """ë„ˆë¬´ ë§¤ìš´ê²ƒì€ ëª»ë¨¹ê³ , ì¹˜ì¦ˆê°€ ë§ì€ í”¼ìë¥¼ ì¢‹ì•„í•˜ë©° ë‹¤ì´ì–´íŠ¸ë¥¼ ìƒê°í•´ì„œ ì•¼ì±„ë¥¼ ë¨¼ì € ë¨¹ëŠ”ê±¸ ì¢‹ì•„í•¨. 
            ìœ¡ë¥˜ë„ ì¢‹ì•„í•˜ë©° í•´ì‚°ë¬¼ ë° íšŒ ë˜í•œ ì¢‹ì•„í•˜ëŠ” í¸ì´ê³  ë„ˆë¬´ ì•¼ì±„ë§Œ ë§ì€ ìŒì‹ì€ ë³„ë¡œ ì¢‹ì•„í•˜ì§€ ì•Šê³  ëƒ„ìƒˆê°€ ë§ì´ ë‚˜ëŠ” ìŒì‹ë„ ë³„ë¡œ ì¢‹ì•„í•˜ì§€ ì•ŠìŒ."""

            now_time = get_local_time_by_gps(latitude, longitude)
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
            system_prompt = f"""
# Restaurant Recommendation Expert System

## Primary Role
You are a specialized assistant that recommends restaurants to travelers based on their current location and time.

## Core Responsibilities
- Analyze user's current location (latitude/longitude) and time
- Write the Reason for the recommendation as detail as possible but not too long.
- Consider user preferences: `{user_preference}`
- Provide detailed restaurant recommendations in Korean language only
- Use a friendly, detailed communication style

## Recommendation Process (Chain of Thought)
1. **Gather Location Data**: First, Check the user's current location and nearby area from the user's prompt
2. **Search Nearby Options**: Use function call to retrieve 20 nearby restaurants
   ```
   Function parameters:
   - latitude: [Use provided user latitude]
   - longitude: [Use provided user longitude]
   - keyword: "restaurant" (default, adjust based on preferences)
   ```
3. **Filter Results**: From the 20 returned options, select 5 best matches based on:
   - Proximity to user's location
   - Alignment with stated preferences
   - Variety of cuisine types
   - Current operational status (based on time)

4. **Format Recommendations**: For each selected restaurant, provide:
   - Name and cuisine type
   - Key distinguishing features
   - Specific dish recommendations
   - Reason for recommendation
   - Approximate distance from current location

## Output Requirements
- **MUST Respond exclusively in Korean language**
- **MUST Response with only your outputs in Markdown format Not Json style**
- Use polite, friendly tone
- Provide comprehensive details for each recommendation
- Present 5 curated options from the function search results

## Note
The function search results will be listed in order of proximity to the user's current location. Street and city information is provided as user prompt.

"""         
            restaurant_history = []
            # LLM ìš”ì²­ - ì‹¤ì œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¶”ì²œ ìƒì„±
            llm_response = generate_content_with_history(
                system_prompt=system_prompt,
                new_message=f"í˜„ì¬ ì‹œê°„ {now_time}, í˜„ì¬ ìœ„ì¹˜ëŠ” ìœ„ì¹˜(ìœ„ë„ {latitude}, ê²½ë„ {longitude}) ë¶€ê°€ì ì¸ í˜„ì¬ ë„ì‹œì™€ ê±°ë¦¬ëŠ” {city}, {street}.",
                function_list=[maps_search_nearby],
                image_path=None,
                k=7,
                history=restaurant_history
            )
            llm_response = dict(list(llm_response)[1])['content']
            print(llm_response)
        # 2. ì´ë¯¸ì§€ + GPS - ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆì™€ ë¶„ì„ ê²°ê³¼ë¥¼ ì´ìš©í•˜ì—¬ Discord ë©”ì‹œì§€ ì „ì†¡ í›„ ìŒì„± ì „ì†¡
        elif latitude and longitude and image_filename and not audio_filename and not extra_message:
            logging.info("ì¼€ì´ìŠ¤ 2: ì´ë¯¸ì§€ì™€ GPS ì •ë³´ê°€ ìˆëŠ” ê²½ìš° - ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆì™€ ë¶„ì„ ê²°ê³¼ë¥¼ ì´ìš©í•˜ì—¬ Discord ë©”ì‹œì§€ ì „ì†¡ í›„ ìŒì„± ì „ì†¡")
            
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
            system_prompt = """
### **Objective**
Analyze an image and determine if it is an **artwork, museum artifact, general photo, or text/document in a foreign language**.  
Provide detailed **historical and artistic insights** for artworks, engage in a **friendly conversation** for general photos, and offer **translation and analysis** for foreign language text.

---

### **Step 1: Identify Image Type**
- **Is it an artwork or museum artifact?** â†’ If yes, proceed to `Step 2: Artwork Analysis`
- **Is it a general photo (landscape, people, objects, pets, etc.)?** â†’ If yes, proceed to `Step 3: Friendly Conversation`
- **Does it contain text in a foreign language (signs, menus, documents)?** â†’ If yes, proceed to `Step 4: Foreign Text Analysis`

---

### **Step 2: Artwork or Museum Artifact Analysis**
> Provide an in-depth analysis covering these essential elements:

#### **1. Basic Information**
- **Title:** [Artwork Title]
- **Artist:** [Artist Name]
- **Year Created:** [Creation Year]
- **Location:** [Museum/Gallery Name]
- **Medium & Technique:** [Materials Used]
- **Dimensions:** [Size in cm/inches]

#### **2. Historical Context**
- What was happening during the time this artwork was created?
- How does the artist's life connect to the work?

#### **3. Symbolism & Meaning**
- What are the key themes and hidden messages in the artwork?
- What emotions or ideas is the artist trying to convey?

#### **4. Artistic Techniques & Style**
- Which artistic movement or style does it belong to?
- What unique methods were used in composition, color, and texture?

#### **5. Trivia & Interesting Facts**
- Are there any famous controversies, thefts, or mysteries about this piece?
- Has this artwork been referenced in popular culture?

#### **6. Influence & Legacy**
- How has this artwork influenced other artists or movements?
- How is it perceived in modern times?

---

### **Step 3: Friendly Conversation for General Photos**
> If the image is NOT an artwork or museum artifact, engage with the user in a friendly and interactive manner.
Use the user's current location and time from user prompt to make the conversation more engaging.

#### ** Casual & Conversational Style**
- Identify key elements in the image (e.g., people, pets, objects, nature).
- Make observations in a natural, engaging way.
- Ask open-ended questions to involve the user in a dialogue.

#### ** Example Approaches**
- **Pets:** "Aww, what a cute dog! What's their name? "
- **Food:** "That looks delicious! Did you make it yourself or is it from a restaurant?"
- **Nature:** "Such a peaceful view! Where was this taken?"
- **Selfies:** "Great shot! What was the occasion?"

---

### **Step 4: Foreign Text Analysis**
> If the image contains text in a non-Korean language (signs, menus, documents, etc.), provide a comprehensive analysis:

#### **1. Text Identification & Translation**
- Identify the language of the text
- Transcribe the original text
- Provide a complete Korean translation

#### **2. Content Analysis**
- For menus: Explain dishes, ingredients, pricing, and specialties
- For signs: Explain the meaning, context, and any cultural significance
- For documents: Summarize the key information and purpose

#### **3. Cultural Context**
- Provide relevant cultural background information
- Explain any idioms, references, or cultural nuances
- Connect the text to local customs or traditions

#### **4. Practical Information**
- For menus: Recommend dishes or explain unfamiliar ingredients
- For signs: Explain directions, warnings, or instructions
- For documents: Highlight important details the user should know

---

### **Adaptive Style Guidelines**
- **If it's an artwork:** Be **informative, structured, and insightful**.
- **If it's a general photo:** Be **casual, warm, and conversational**.
- **If it's foreign text:** Be **helpful, detailed, and educational**.

### **Output Requirements**
- **MUST Respond with the same language as the user's input**
- **MUST Response with only your outputs in Markdown format Not Json style**
"""
            
            executor = concurrent.futures.ThreadPoolExecutor()

            # ì´ë¯¸ì§€ ìš©ëŸ‰ì´ 8MB ì´ìƒì¼ ë•Œë§Œ ë¦¬ì‚¬ì´ì¦ˆë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
            if os.path.getsize(image_filename) >= 7.5 * 1024 * 1024:
                future_resize = executor.submit(resize_image, image_filename, 7.5)
                resized_image_filename = future_resize.result()
            else:
                resized_image_filename = image_filename

            now_time = get_local_time_by_gps(latitude, longitude)
            image_without_message_history = []
            # Gemini ë¶„ì„ í˜¸ì¶œ
            llm_response = generate_content_with_history(
                system_prompt=system_prompt,
                new_message=f"í˜„ì¬ ì‹œê°„ {now_time}, í˜„ì¬ ìœ„ì¹˜ëŠ” ìœ„ì¹˜(ìœ„ë„ {latitude}, ê²½ë„ {longitude}) ë¶€ê°€ì ì¸ í˜„ì¬ ë„ì‹œì™€ ê±°ë¦¬ëŠ” {city}, {street}.",
                image_path=resized_image_filename,
                k=5,
                function_list=None,
                history=image_without_message_history
            )
            llm_response = dict(list(llm_response)[1])['content']

            # Discord ë©”ì‹œì§€ ì „ì†¡: ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸(ë¶„ì„ ê²°ê³¼)ë¥¼ í¬í•¨í•˜ì—¬ í•œ ë²ˆì— ì „ì†¡
            future_msg = executor.submit(lambda: asyncio.run_coroutine_threadsafe(
                send_location_to_discord(
                    latitude, longitude, street, city,
                    extra_message=llm_response,
                    image_path=resized_image_filename,
                    audio_path=None,
                    show_places=False,
                    message_include=True
                ), bot.loop
            ).result())
            try:
                future_msg.result(timeout=30)
            except Exception as e:
                logging.error(f"ë””ìŠ¤ì½”ë“œ ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨ (ì´ë¯¸ì§€+í…ìŠ¤íŠ¸): {e}")

            # TTS: ìŒì„± í•©ì„±
            import re
            audio_text = re.sub(r'[*_`~#]', '', llm_response)
            response_audio_filename = os.path.join(RESPONSE_FOLDER, f"response_{int(time.time())}.mp3")
            tts_success = synthesize_speech(audio_text, response_audio_filename)
            if tts_success:
                future_audio = executor.submit(lambda: asyncio.run_coroutine_threadsafe(
                    send_location_to_discord(
                        latitude, longitude, street, city,
                        extra_message="ìŒì„± ì‘ë‹µ",
                        image_path=None,
                        audio_path=response_audio_filename,
                        show_places=False,
                        message_include=False
                    ), bot.loop
                ).result())
                try:
                    future_audio.result(timeout=30)
                except Exception as e:
                    logging.error(f"ë””ìŠ¤ì½”ë“œ ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨ (ìŒì„±): {e}")
            else:
                logging.error("TTS ìŒì„± í•©ì„± ì‹¤íŒ¨")

            executor.shutdown(wait=True)
            discord_sent = True
            return jsonify({'status': 'success'})
        
        # 3. ì´ë¯¸ì§€ + ë©”ì‹œì§€ + GPS - ë©”ì‹œì§€ë¥¼ í”„ë¡¬í”„íŠ¸ë¡œ ì‚¬ìš©
        elif latitude and longitude and image_filename and not audio_filename and extra_message:
            logging.info("ì¼€ì´ìŠ¤ 3: ì´ë¯¸ì§€ + ë©”ì‹œì§€ + GPS - ë©”ì‹œì§€ë¥¼ ê·¸ëŒ€ë¡œ í”„ë¡¬í”„íŠ¸ë¡œ ì‚¬ìš©")
            now_time = get_local_time_by_gps(latitude, longitude)
            # ê¸°ë³¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            system_prompt = f"""
# Multimodal Assistant

## Primary Role
You are a specialized multimodal assistant with functions based on user's current location and time.

## Core Responsibilities
- Be aware of user's current location (latitude/longitude) and time Not always use but you can use whenever you needed.
- Use a friendly, detailed communication style
- Analyze an image and determine if it is an **artwork, museum artifact, general photo, or text/document in a foreign language**.  
- Provide detailed **historical and artistic insights** for artworks, engage in a **friendly conversation** for general photos, and offer **translation and analysis** for foreign language text.
- **Following these responsibilities if user does not provide any prompt but if user provide prompt, you must follow user's prompt based on these instructions.**

### **Step 1: Identify Image Type**
- **Is it an artwork or museum artifact?** â†’ If yes, proceed to `Step 2: Artwork Analysis`
- **Is it a general photo (landscape, people, objects, pets, etc.)?** â†’ If yes, proceed to `Step 3: Friendly Conversation`
- **Does it contain text in a foreign language (signs, menus, documents)?** â†’ If yes, proceed to `Step 4: Foreign Text Analysis`
---

### **Step 2: Artwork or Museum Artifact Analysis**
> Provide an in-depth analysis covering these essential elements:

#### **1. Basic Information**
- **Title:** [Artwork Title]
- **Artist:** [Artist Name]
- **Year Created:** [Creation Year]
- **Location:** [Museum/Gallery Name]
- **Medium & Technique:** [Materials Used]
- **Dimensions:** [Size in cm/inches]

#### **2. Historical Context**
- What was happening during the time this artwork was created?
- How does the artist's life connect to the work?

#### **3. Symbolism & Meaning**
- What are the key themes and hidden messages in the artwork?
- What emotions or ideas is the artist trying to convey?

#### **4. Artistic Techniques & Style**
- Which artistic movement or style does it belong to?
- What unique methods were used in composition, color, and texture?

#### **5. Trivia & Interesting Facts**
- Are there any famous controversies, thefts, or mysteries about this piece?
- Has this artwork been referenced in popular culture?

#### **6. Influence & Legacy**
- How has this artwork influenced other artists or movements?
- How is it perceived in modern times?

---

### **Step 3: Friendly Conversation for General Photos**
> If the image is NOT an artwork or museum artifact, engage with the user in a friendly and interactive manner.
Use the user's current location and time from user prompt to make the conversation more engaging.

#### ** Casual & Conversational Style**
- Identify key elements in the image (e.g., people, pets, objects, nature).
- Make observations in a natural, engaging way.
- Ask open-ended questions to involve the user in a dialogue.

#### ** Example Approaches**
- **Pets:** "Aww, what a cute dog! What's their name? "
- **Food:** "That looks delicious! Did you make it yourself or is it from a restaurant?"
- **Nature:** "Such a peaceful view! Where was this taken?"
- **Selfies:** "Great shot! What was the occasion?"

---

### **Step 4: Foreign Text Analysis**
> If the image contains text in a non-user prompt language (signs, menus, documents, etc.), provide a comprehensive analysis:

#### **1. Text Identification & Translation**
- Identify the language of the text
- Transcribe the original text
- Provide a complete translation in user prompt language
- Show original text in parentheses next to translation to understand foreign text in the image well.

#### **2. Content Analysis**
- For menus: Explain dishes, ingredients, pricing, and specialties
- For signs: Explain the meaning, context, and any cultural significance
- For documents: Summarize the key information and purpose

#### **3. Cultural Context**
- Provide relevant cultural background information
- Explain any idioms, references, or cultural nuances
- Connect the text to local customs or traditions

#### **4. Practical Information**
- For menus: Recommend dishes or explain unfamiliar ingredients
- For signs: Explain directions, warnings, or instructions
- For documents: Highlight important details the user should know

---

## Location and Time Parameters
- Use the provided `{latitude}`, `{longitude}`, `{city}`, `{street}`, and `{now_time}` as the basis for recommendations
- These parameters represent the user's current context for providing relevant suggestions

## Response Guidelines
- **MUST Respond to prompts in languages in their respective language from user prompt**
- Provide friendly, appropriately-sized responses based on the user's query
- Adjust detail level based on the nature of the user's request

## Using Internet Search Function
1. **Gather Data**: Determine when you need information you don't know or need to be updated.
2. **Use get_search_results function**: Use function call to retrieve several search results by DuckDuckGo

   Function parameters:
   - query: YOUR QUERY
   ```
3. **Filter Results**: 
   - Process search results by analyzing the returned titles and snippets
   - Summarize the information in the user's input language, even if search results are in different languages
   - Include relevant citations as references at the end of your response
   - Translate if needed - ensure all information is presented in the user's preferred language regardless of the language of search results


## Using Nearby Search Function
1. **Gather Data**: Determine when you need information you don't know or need to be updated.
2. **Use maps_search_nearby function**: Use function call to retrieve several search results by Google Maps
   ```
   Function parameters:
   - latitude: user's current latitude
   - longitude: user's current longitude
   - keyword: Your Keyword (eg. hotel, restaurant, park, etc.)
   ```
3. **Filter Results**: 
   - Process search results by analyzing the returned titles and snippets
   - Summarize the information in the user's input language, even if search results are in different languages
   - Present 5 best matches to the user based on distance, rate, name and explain why you recommend them
   - Translate if needed - ensure all information is presented in the user's preferred language regardless of the language of search results

## Recommendation Format
For each selected restaurant, provide:
- Use Natural language to user whether you use function or not
- If you use function, provide more structured and detailed information about the search results

## Output Requirements
- Match response language to input language
- Use polite, friendly tone
- Write in Markdown format for better readability
- Include references to search results when applicable

"""
            executor = concurrent.futures.ThreadPoolExecutor()
            # ì´ë¯¸ì§€ ìš©ëŸ‰ì´ 8MB ì´ìƒì¼ ë•Œë§Œ ë¦¬ì‚¬ì´ì¦ˆë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
            if os.path.getsize(image_filename) >= 7.5 * 1024 * 1024:
                future_resize = executor.submit(resize_image, image_filename, 7.5)
                resized_image_filename = future_resize.result()
            else:
                resized_image_filename = image_filename

            # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ê·¸ëŒ€ë¡œ í”„ë¡¬í”„íŠ¸ë¡œ ì‚¬ìš©
            llm_response = generate_content_with_history(
                system_prompt=system_prompt,
                new_message=extra_message,
                image_path=resized_image_filename,
                function_list=[get_search_results]
            )
            llm_response = dict(list(llm_response)[1])['content']
        
        # 4. ì´ë¯¸ì§€ + ì˜¤ë””ì˜¤ + GPS - ì˜¤ë””ì˜¤ ë³€í™˜ í›„ ì²˜ë¦¬
        elif latitude and longitude and image_filename and audio_filename and not extra_message:
            logging.info("ì¼€ì´ìŠ¤ 4: ì´ë¯¸ì§€ + ì˜¤ë””ì˜¤ + GPS - ì˜¤ë””ì˜¤ ë³€í™˜ í›„ ì²˜ë¦¬")
            
            # ì˜¤ë””ì˜¤ íŒŒì¼ í™•ì¥ì í™•ì¸ ë° ë³€í™˜
            audio_ext = os.path.splitext(audio_filename)[1].lower()
            mp3_audio_path = audio_filename
            
            # m4a íŒŒì¼ì´ë©´ mp3ë¡œ ë³€í™˜
            if audio_ext == '.m4a':
                mp3_audio_path = convert_m4a_to_mp3_moviepy(audio_filename)
            
            # ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (medium ëª¨ë¸ ì‚¬ìš©)
            transcribed_text = transcribe_audio(mp3_audio_path, "medium")
            
            if transcribed_text and isinstance(transcribed_text, str):
                logging.info(f"ì˜¤ë””ì˜¤ í…ìŠ¤íŠ¸ ë³€í™˜ ê²°ê³¼: {transcribed_text}")
                now_time = get_local_time_by_gps(latitude, longitude)
                
                # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
                system_prompt = f"""
# Multimodal Assistant

## Primary Role
You are a specialized multimodal assistant with functions based on user's current location and time.

## Core Responsibilities
- Be aware of user's current location (latitude/longitude) and time Not always use but you can use whenever you needed.
- Use a friendly, detailed communication style
- Analyze an image and determine if it is an **artwork, museum artifact, general photo, or text/document in a foreign language**.  
- Provide detailed **historical and artistic insights** for artworks, engage in a **friendly conversation** for general photos, and offer **translation and analysis** for foreign language text.
- **Following these responsibilities if user does not provide any prompt but if user provide prompt, you must follow user's prompt based on these instructions.**

### **Step 1: Identify Image Type**
- **Is it an artwork or museum artifact?** â†’ If yes, proceed to `Step 2: Artwork Analysis`
- **Is it a general photo (landscape, people, objects, pets, etc.)?** â†’ If yes, proceed to `Step 3: Friendly Conversation`
- **Does it contain text in a foreign language (signs, menus, documents)?** â†’ If yes, proceed to `Step 4: Foreign Text Analysis`
---

### **Step 2: Artwork or Museum Artifact Analysis**
> Provide an in-depth analysis covering these essential elements:

#### **1. Basic Information**
- **Title:** [Artwork Title]
- **Artist:** [Artist Name]
- **Year Created:** [Creation Year]
- **Location:** [Museum/Gallery Name]
- **Medium & Technique:** [Materials Used]
- **Dimensions:** [Size in cm/inches]

#### **2. Historical Context**
- What was happening during the time this artwork was created?
- How does the artist's life connect to the work?

#### **3. Symbolism & Meaning**
- What are the key themes and hidden messages in the artwork?
- What emotions or ideas is the artist trying to convey?

#### **4. Artistic Techniques & Style**
- Which artistic movement or style does it belong to?
- What unique methods were used in composition, color, and texture?

#### **5. Trivia & Interesting Facts**
- Are there any famous controversies, thefts, or mysteries about this piece?
- Has this artwork been referenced in popular culture?

#### **6. Influence & Legacy**
- How has this artwork influenced other artists or movements?
- How is it perceived in modern times?

---

### **Step 3: Friendly Conversation for General Photos**
> If the image is NOT an artwork or museum artifact, engage with the user in a friendly and interactive manner.
Use the user's current location and time from user prompt to make the conversation more engaging.

#### ** Casual & Conversational Style**
- Identify key elements in the image (e.g., people, pets, objects, nature).
- Make observations in a natural, engaging way.
- Ask open-ended questions to involve the user in a dialogue.

#### ** Example Approaches**
- **Pets:** "Aww, what a cute dog! What's their name? "
- **Food:** "That looks delicious! Did you make it yourself or is it from a restaurant?"
- **Nature:** "Such a peaceful view! Where was this taken?"
- **Selfies:** "Great shot! What was the occasion?"

---

### **Step 4: Foreign Text Analysis**
> If the image contains text in a non-user prompt language (signs, menus, documents, etc.), provide a comprehensive analysis:

#### **1. Text Identification & Translation**
- Identify the language of the text
- Transcribe the original text
- Provide a complete translation in user prompt language
- Show original text in parentheses next to translation to understand foreign text in the image well.

#### **2. Content Analysis**
- For menus: Explain dishes, ingredients, pricing, and specialties
- For signs: Explain the meaning, context, and any cultural significance
- For documents: Summarize the key information and purpose

#### **3. Cultural Context**
- Provide relevant cultural background information
- Explain any idioms, references, or cultural nuances
- Connect the text to local customs or traditions

#### **4. Practical Information**
- For menus: Recommend dishes or explain unfamiliar ingredients
- For signs: Explain directions, warnings, or instructions
- For documents: Highlight important details the user should know

---

## Location and Time Parameters
- Use the provided `{latitude}`, `{longitude}`, `{city}`, `{street}`, and `{now_time}` as the basis for recommendations
- These parameters represent the user's current context for providing relevant suggestions

## Response Guidelines
- **MUST Respond to prompts in languages in their respective language from user prompt**
- Provide friendly, appropriately-sized responses based on the user's query
- Adjust detail level based on the nature of the user's request

## Using Internet Search Function
1. **Gather Data**: Determine when you need information you don't know or need to be updated.
2. **Use get_search_results function**: Use function call to retrieve several search results by DuckDuckGo

   Function parameters:
   - query: YOUR QUERY
   ```
3. **Filter Results**: 
   - Process search results by analyzing the returned titles and snippets
   - Summarize the information in the user's input language, even if search results are in different languages
   - Include relevant citations as references at the end of your response
   - Translate if needed - ensure all information is presented in the user's preferred language regardless of the language of search results


## Using Nearby Search Function
1. **Gather Data**: Determine when you need information you don't know or need to be updated.
2. **Use maps_search_nearby function**: Use function call to retrieve several search results by Google Maps
   ```
   Function parameters:
   - latitude: user's current latitude
   - longitude: user's current longitude
   - keyword: Your Keyword (eg. hotel, restaurant, park, etc.)
   ```
3. **Filter Results**: 
   - Process search results by analyzing the returned titles and snippets
   - Summarize the information in the user's input language, even if search results are in different languages
   - Present 5 best matches to the user based on distance, rate, name and explain why you recommend them
   - Translate if needed - ensure all information is presented in the user's preferred language regardless of the language of search results

## Recommendation Format
For each selected restaurant, provide:
- Use Natural language to user whether you use function or not
- If you use function, provide more structured and detailed information about the search results

## Output Requirements
- Match response language to input language
- Use polite, friendly tone
- Write in Markdown format for better readability
- Include references to search results when applicable

"""
                executor = concurrent.futures.ThreadPoolExecutor()
                # ì´ë¯¸ì§€ ìš©ëŸ‰ì´ 8MB ì´ìƒì¼ ë•Œë§Œ ë¦¬ì‚¬ì´ì¦ˆë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
                if os.path.getsize(image_filename) >= 7.5 * 1024 * 1024:
                    future_resize = executor.submit(resize_image, image_filename, 7.5)
                    resized_image_filename = future_resize.result()
                else:
                    resized_image_filename = image_filename

                # LLM ìš”ì²­ - ì‚¬ìš©ì ìŒì„± ë©”ì‹œì§€ë¥¼ ê·¸ëŒ€ë¡œ ì²˜ë¦¬
                llm_response = generate_content_with_history(
                    system_prompt=system_prompt,
                    new_message=transcribed_text,
                    image_path=resized_image_filename,
                    function_list=[get_search_results]
                )
                llm_response = dict(list(llm_response)[1])['content']
            else:
                llm_response = "ìŒì„± ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        
        # 5-1. ë©”ì‹œì§€ + GPS - ë©”ì‹œì§€ë¥¼ í”„ë¡¬í”„íŠ¸ë¡œ ì‚¬ìš©
        elif latitude and longitude and not image_filename and not audio_filename and extra_message:
            logging.info("ì¼€ì´ìŠ¤ 5-1: ë©”ì‹œì§€ + GPS - ë©”ì‹œì§€ë¥¼ ê·¸ëŒ€ë¡œ í”„ë¡¬í”„íŠ¸ë¡œ ì‚¬ìš©")
            now_time = get_local_time_by_gps(latitude, longitude)
            
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
            system_prompt = f"""
# Multimodal Assistant

## Primary Role
You are a specialized assistant based on user's current location and time.

## Core Responsibilities
- Be aware of user's current location (latitude/longitude) and time
- Use a friendly, detailed communication style

## Location and Time Parameters
- Use the provided `{latitude}`, `{longitude}`, `{city}`, `{street}`, and `{now_time}` as the basis for recommendations
- These parameters represent the user's current context for providing relevant suggestions

## Response Guidelines
- **MUST Respond to prompts in languages in their respective language from user prompt**
- Provide friendly, appropriately-sized responses based on the user's query
- Adjust detail level based on the nature of the user's request

## Using Internet Search Function
1. **Gather Data**: Determine when you need information you don't know or need to be updated.
2. **Use get_search_results function**: Use function call to retrieve several search results by DuckDuckGo

   Function parameters:
   - query: YOUR QUERY
   ```
3. **Filter Results**: 
   - Process search results by analyzing the returned titles and snippets
   - Summarize the information in the user's input language, even if search results are in different languages
   - Include relevant citations as references at the end of your response
   - Translate if needed - ensure all information is presented in the user's preferred language regardless of the language of search results


## Using Nearby Search Function
1. **Gather Data**: Determine when you need information you don't know or need to be updated.
2. **Use maps_search_nearby function**: Use function call to retrieve several search results by Google Maps
   ```
   Function parameters:
   - latitude: user's current latitude
   - longitude: user's current longitude
   - keyword: Your Keyword (eg. hotel, restaurant, park, etc.)
   ```
3. **Filter Results**: 
   - Process search results by analyzing the returned titles and snippets
   - Summarize the information in the user's input language, even if search results are in different languages
   - Present 5 best matches to the user based on distance, rate, name and explain why you recommend them
   - Translate if needed - ensure all information is presented in the user's preferred language regardless of the language of search results

## Recommendation Format
For each selected restaurant, provide:
- Use Natural language to user whether you use function or not
- If you use function, provide more structured and detailed information about the search results

## Output Requirements
- Match response language to input language
- Use polite, friendly tone
- Write in Markdown format for better readability
- Include references to search results when applicable

"""
            
            # LLM ìš”ì²­ - ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ê·¸ëŒ€ë¡œ ì²˜ë¦¬
            llm_response = generate_content_with_history(
                system_prompt=system_prompt,
                new_message=extra_message,
                function_list=[get_search_results, maps_search_nearby],
                image_path=None
            )
            llm_response = dict(list(llm_response)[1])['content']
        # 5-2. ì˜¤ë””ì˜¤ + GPS - ì˜¤ë””ì˜¤ ë³€í™˜ í›„ ì²˜ë¦¬
        elif latitude and longitude and not image_filename and audio_filename and not extra_message:
            logging.info("ì¼€ì´ìŠ¤ 5-2: ì˜¤ë””ì˜¤ + GPS - ì˜¤ë””ì˜¤ ë³€í™˜ í›„ ì²˜ë¦¬")
            
            # ì˜¤ë””ì˜¤ íŒŒì¼ í™•ì¥ì í™•ì¸ ë° ë³€í™˜
            audio_ext = os.path.splitext(audio_filename)[1].lower()
            mp3_audio_path = audio_filename
            
            # m4a íŒŒì¼ì´ë©´ mp3ë¡œ ë³€í™˜
            if audio_ext == '.m4a':
                mp3_audio_path = convert_m4a_to_mp3_moviepy(audio_filename)
            
            # ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            transcribed_text = transcribe_audio(mp3_audio_path, "medium")
            
            if transcribed_text and isinstance(transcribed_text, str):
                logging.info(f"ì˜¤ë””ì˜¤ í…ìŠ¤íŠ¸ ë³€í™˜ ê²°ê³¼: {transcribed_text}")
                now_time = get_local_time_by_gps(latitude, longitude)
                
                # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
                system_prompt = f"""
# Multimodal Assistant

## Primary Role
You are a specialized assistant based on user's current location and time.

## Core Responsibilities
- Be aware of user's current location (latitude/longitude) and time
- Use a friendly, detailed communication style

## Location and Time Parameters
- Use the provided `{latitude}`, `{longitude}`, `{city}`, `{street}`, and `{now_time}` as the basis for recommendations
- These parameters represent the user's current context for providing relevant suggestions

## Response Guidelines
- **MUST Respond to prompts in languages in their respective language from user prompt**
- Provide friendly, appropriately-sized responses based on the user's query
- Adjust detail level based on the nature of the user's request

## Using Internet Search Function
1. **Gather Data**: Determine when you need information you don't know or need to be updated.
2. **Use get_search_results function**: Use function call to retrieve several search results by DuckDuckGo

   Function parameters:
   - query: YOUR QUERY
   ```
3. **Filter Results**: 
   - Process search results by analyzing the returned titles and snippets
   - Summarize the information in the user's input language, even if search results are in different languages
   - Include relevant citations as references at the end of your response
   - Translate if needed - ensure all information is presented in the user's preferred language regardless of the language of search results


## Using Nearby Search Function
1. **Gather Data**: Determine when you need information you don't know or need to be updated.
2. **Use maps_search_nearby function**: Use function call to retrieve several search results by Google Maps
   ```
   Function parameters:
   - latitude: user's current latitude
   - longitude: user's current longitude
   - keyword: Your Keyword (eg. hotel, restaurant, park, etc.)
   ```
3. **Filter Results**: 
   - Process search results by analyzing the returned titles and snippets
   - Summarize the information in the user's input language, even if search results are in different languages
   - Present 5 best matches to the user based on distance, rate, name and explain why you recommend them
   - Translate if needed - ensure all information is presented in the user's preferred language regardless of the language of search results

## Recommendation Format
For each selected restaurant, provide:
- Use Natural language to user whether you use function or not
- If you use function, provide more structured and detailed information about the search results

## Output Requirements
- Match response language to input language
- Use polite, friendly tone
- Write in Markdown format for better readability
- Include references to search results when applicable

"""
                
                # LLM ìš”ì²­ - ì‚¬ìš©ì ìŒì„± ë©”ì‹œì§€ë¥¼ ê·¸ëŒ€ë¡œ ì²˜ë¦¬
                llm_response = generate_content_with_history(
                    system_prompt=system_prompt,
                    new_message=transcribed_text,
                    function_list=[get_search_results, maps_search_nearby],
                    image_path=None
                )
                llm_response = dict(list(llm_response)[1])['content']

            else:
                llm_response = "ìŒì„± ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                
        # ê¸°íƒ€ ë‹¤ë¥¸ ì¼€ì´ìŠ¤ë“¤ - ê¸°ë³¸ ì²˜ë¦¬
        else:
            logging.info("ê¸°íƒ€ ì¼€ì´ìŠ¤: ê¸°ë³¸ ì²˜ë¦¬")
            # ë””ìŠ¤ì½”ë“œë¡œ ì „ì†¡í•  ê¸°ë³¸ ë©”ì‹œì§€ ìƒì„±
            extra_message_content = f"GPS: {latitude}, {longitude}"
            if street or city:
                extra_message_content += f", ì£¼ì†Œ: {street}, {city}"
            
            if extra_message:
                extra_message_content += f"\n\nì‚¬ìš©ì ë©”ì‹œì§€: {extra_message}"
            
            # ì¶”ê°€ ë©”ì‹œì§€ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ LLM ì‘ë‹µ ìƒì„±
            if not llm_response:
                llm_response = "ì œê³µëœ ì •ë³´ë¥¼ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤."

        # ì²˜ë¦¬ ê²°ê³¼ ë° ìµœì¢… ë©”ì‹œì§€ ì •ë¦¬
        if not discord_sent:
            response_message = extra_message if extra_message else "ì²˜ë¦¬ëœ ë°ì´í„°"

            if llm_response:
                response_message = llm_response

            # ë””ìŠ¤ì½”ë“œë¡œ ì „ì†¡ (ë¹„ë™ê¸°) - ë§›ì§‘ ì •ë³´ëŠ” í‘œì‹œí•˜ì§€ ì•ŠìŒ
            future = asyncio.run_coroutine_threadsafe(
                send_location_to_discord(
                    latitude, longitude, street, city,
                    extra_message=response_message,
                    image_path=resized_image_filename,
                    audio_path=response_audio if response_audio else audio_filename,
                    show_places=False  # ì£¼ë³€ ì¥ì†Œ ì •ë³´ í‘œì‹œí•˜ì§€ ì•ŠìŒ
                ),
                bot.loop
            )
            try:
                future.result(timeout=30)
            except concurrent.futures.TimeoutError:
                logging.error("ë””ìŠ¤ì½”ë“œ ë©”ì‹œì§€ ì „ì†¡ ì‹œê°„ ì´ˆê³¼")
            except Exception as e:
                logging.error(f"ë””ìŠ¤ì½”ë“œ ì „ì†¡ ì¤‘ ì˜¤ë¥˜: {e}")

        return jsonify({
            "status": "success",
            "filename": resized_image_filename,
            "audio_filename": audio_filename,
            "response_audio": response_audio,
            "message": extra_message,
            "llm_response": llm_response,
            "latitude": latitude,
            "longitude": longitude,
            "street": street,
            "city": city
        }), 200

    except Exception as e:
        logging.exception("ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì—ëŸ¬:")
        return jsonify({"error": str(e)}), 500

# %%
